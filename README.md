## RU


# Airbnb парсер djj

**Что делает:**

Парсер данных сайта Airbnb на python библиотеках Beautiful Soup 4 и Selenium. Собранные данные размещает в реляционной базе данных PostgreSQL. Так же задумана аналитика данных.

**Готовность:** 

Собирает, вносит в базу, бот выдает в таблице банные, фильтры, статистика, в новой ветке работает в Docker-compose.

**Как запустить:** 

- Установить google chrome, docker, docker-compose в Linux сервера.

- Колонировать репозиторий git clone _имя репозитория_

- Установить виртуальное окружение в эту папку, запустить

- Создать в корне папки файл .env заполнить его по аналогии с файлом example-env, т. е. придумать имя пользователя и пароль базы данных, токен телеграм, при необходимости Yndex Геокодер.

- В файле Dockerfile все раскоментировать - это установить все библиотеки через pip при запуске контейнера.

- При деплое на сервер, нужно изменить имя файла "pg_hba.conf-ex" на имя - "pg_hba.conf". Этот файл запрещает доступ к базе акромя локали.

- Поднять docker-compose up --build. Установятся связи. Запуститься база. Запустятся сервисы описанные в Docker-compose.

- Можно запустить только базу в докере и просто запускать файлы python: parser_list.py - парсер списков id  url, parser_object.py - парсер объекта, bot.py - запуск телеграмм бота.


Пример окна бота:

<img src="https://github.com/shliamb/airbnb/blob/main/img/9.png?raw=true" alt="Airbnb" width="auto" height="auto" align="top">


Сайт Airbnb "кусается". При длительном парсинге страниц, блокируется доступ к сайту. Решилось автоматическим удалением и созданием новых профилей браузера.

<img src="https://github.com/shliamb/airbnb/blob/main/img/5.png?raw=true" alt="Airbnb" width="auto" height="auto" align="top">


# Логика работы приложений

Для ускорения, парсер разделен на два приложения.

**Парсер списков**

Парсер списков собирает в отдельную таблицу - Id значения id и URL объектов, заходя на страницы поиска с вилкой стоимости +1$. Т.е. от 10$ до 11$ и так далее. Связанно это с тем, что выдача поисковой страницы выдает только 15 вкладок. Но парсер автоматический и задуман работать на постоянной основе, собирая в базу все больше объектов.

В качестве главного идентификатора в базе выбран id объекта, так же как и на сайте Airbnb и Airdna. Приложение независимо. Автоматически очищаеет профиля в целях защиты от блокировки сайтом. Приложение сохраняет вилку цен. Таким образом, при непредвиденной остановке, парсер продолжит свою работу с того же места, на котором и остановился.

**Парсер объектов**

Парсер объектов - это тоже самостоятельное приложение. Оно обращается к базе данных. забирает установленное колличество записей (задается переменной, например 10 штук) id и url. При этом, оно забирает те, которые помечены как не пройденые, так же, помеченные как не занятые.

Забрав эти данные, парсер тут же раставляет этим id флаг - заняты. Сделанно это для того, что бы другие парсеры (можно добавлять много парсеров объектов для скорости работы) не брали их в свою работу.

Парсер обходит каждый объект, забирает необходимые данные и вносит их в отдельную таблицу базы данных Airbnb. При этом вносит в эту таблицу id и url которые только что забрал для парсинга, тем самым дублируя их в этой таблице, для последующего уменьшения запросов к таблицам.

Собрав данные с забраных id, парсер переписывает флаги айдишников - не заняты, так же устанавливает флаг  - пройдены. И ерет следующую партию id. 

Парсер работает автоматически. Если вдруг в базе Id нет свободных записей для обхода, парсе берет простой в 5 минут и пробует снова и так по кругу.

Таких парсеров можно запустить скольугодно, ограничение - железо. Главное разделять драйвера браузера. Позже сделаю отдельный класс для автоматического разделения, а не так как сейчас - ручное.

**Телеграммбот**

Простой бот на библиотеке Телебот. Возможно, позже, можно будет переделать на аиограмм, при необходимости.


**Какие улучшения в перспективе парсера вижу я**

- aiogram

- 2 парсера по спискам. Один оходит только ценновые вилки где почти нету недвиги - это долго, но все же нужно, пусть копает. Второй по вилке где основная недвига, где можно натыкаться на все новые объекты, ввиду алгоритма сайта.

- Отдельное логирование приложений, которые можно скачать и посмотреть с бота.

- Контроль входящих пользователей телеграмм бота, блокирования одних и предоставление сверх доступа другим.

- Автоматический бекап базы и по запросу из меню бота с возможностью скачать на телефон, примерно 5 мгб. Можно так же попробовать сделать восстановление базы из файла в телеграмм (у меня в чат боте такое работает).

- Сделать более простое изменение html классов и тегов, которые возможно будут меняться со временем, для упрощения работы в долгосрок.

- Кнопки принудительного сброса флагов переобхода списков.

- Можно придумать флаги внутри парсеров, изменение которых, даст возможность передать в бота информацию о состоянии бота, при необходимости.

... пока что все, при оплате, работа продолжится.
